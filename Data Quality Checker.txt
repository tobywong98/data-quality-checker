import pandas as pd
import numpy as np
from oracle_data_connector import DBQuery
from postgresql_data_connector import DBQuery_SQL
from tab_cmd import tableau_export, tableau_export_csv, tableau_login, tableau_logout
from util import period_to_date
import datetime
today = datetime.date.today()
yesterday = today - datetime.timedelta(days=1)
yyesterday = yesterday - datetime.timedelta(days=1)

class tab:

    def _init_(self):
        self.output_df = pd.DataFrame
        self.tlist = []
        self.making_df()
        self.run()

    def add_column(self, df_name, method_value, period_value):
        df_name['method'] = method_value
        df_name['period_type'] = period_value

    def clean_amount(self, x):
        if isinstance(x, str):
            return (x.replace(',', ''))
        return (x)

    def get_csv(self):
        tableau_login("ericawang", "da-dev")
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_sales_info_sum_YTD", "tableau_rt_sales_info_sum_YTD.csv",
                           sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_sales_info_count_YTD", "tableau_rt_sales_info_count_YTD.csv",
                           sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_sales_info_countd_yesterday",
                           "tableau_rt_sales_info_countd_yesterday.csv", sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_shop_info_countd", "tableau_rt_shop_info_countd.csv",
                           sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_inv_cur_count", "tableau_rt_inv_cur_count_.csv",
                           sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_inv_cur_countd", "tableau_rt_inv_cur_countd.csv", sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_inv_cur_sum", "tableau_rt_inv_cur_sum.csv", sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_inv_mth_countd", "tableau_rt_inv_mth_countd.csv", sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_inv_mth_sum", "tableau_rt_inv_mth_sum.csv", sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_inv_mth_count", "tableau_rt_inv_mth_count.csv", sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_dtarget_countd_yesterday",
                           "tableau_rt_dtarget_countd_yesterday.csv", sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_dtarget_count_YTD", "tableau_rt_dtarget_count_YTD.csv",
                           sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_dtarget_sum_YTD", "tableau_rt_dtarget_sum_YTD.csv", sleep=3)
        tableau_export_csv("data_QA_Bon_testing/tableau_rt_vip_mas_countd", "tableau_rt_vip_mas_countd.csv", sleep=3)
        tableau_logout()

    def making_df(self):
        self.tableau_rt_sales_info_sum_YTD = pd.DataFrame
        self.tableau_rt_sales_info_count_YTD = pd.DataFrame
        self.tableau_rt_sales_info_countd_yesterday = pd.DataFrame
        self.tableau_rt_shop_info_countd = pd.DataFrame
        self.tableau_rt_inv_cur_count = pd.DataFrame
        self.tableau_rt_inv_cur_countd = pd.DataFrame
        self.tableau_rt_inv_cur_sum = pd.DataFrame
        self.tableau_rt_inv_mth_countd = pd.DataFrame
        self.tableau_rt_inv_mth_sum = pd.DataFrame
        self.tableau_rt_inv_mth_count = pd.DataFrame
        self.tableau_rt_dtarget_countd_yesterday = pd.DataFrame
        self.tableau_rt_dtarget_count_YTD = pd.DataFrame
        self.tableau_rt_dtarget_sum_YTD = pd.DataFrame
        self.tableau_rt_vip_mas_countd = pd.DataFrame

    def read_csv(self):
        self.tableau_rt_sales_info_sum_YTD = pd.read_csv('tableau_rt_sales_info_sum_YTD.csv')
        self.tableau_rt_sales_info_count_YTD = pd.read_csv('tableau_rt_sales_info_count_YTD.csv')
        self.tableau_rt_sales_info_countd_yesterday = pd.read_csv('tableau_rt_sales_info_countd_yesterday.csv')
        self.tableau_rt_shop_info_countd = pd.read_csv('tableau_rt_shop_info_countd.csv')
        self.tableau_rt_inv_cur_count = pd.read_csv('tableau_rt_inv_cur_count.csv')
        self.tableau_rt_inv_cur_countd = pd.read_csv('tableau_rt_inv_cur_countd.csv')
        self.tableau_rt_inv_cur_sum = pd.read_csv('tableau_rt_inv_cur_sum.csv')
        self.tableau_rt_inv_mth_countd = pd.read_csv('tableau_rt_inv_mth_countd.csv')
        self.tableau_rt_inv_mth_sum = pd.read_csv('tableau_rt_inv_mth_sum.csv')
        self.tableau_rt_inv_mth_count = pd.read_csv('tableau_rt_inv_mth_count.csv')
        self.tableau_rt_dtarget_countd_yesterday = pd.read_csv('tableau_rt_dtarget_countd_yesterday.csv')
        self.tableau_rt_dtarget_count_YTD = pd.read_csv('tableau_rt_dtarget_count_YTD.csv')
        self.tableau_rt_dtarget_sum_YTD = pd.read_csv('tableau_rt_dtarget_sum_YTD.csv')
        self.tableau_rt_vip_mas_countd = pd.read_csv('tableau_rt_vip_mas_countd.csv')

    def adding_col(self):
        self.add_column(self.tableau_rt_sales_info_sum_YTD, 'sum', 'ytd')
        self.add_column(self.tableau_rt_sales_info_count_YTD, 'rowcount', 'ytd')
        self.add_column(self.tableau_rt_sales_info_countd_yesterday, 'countd', 'yesterday')
        self.add_column(self.tableau_rt_shop_info_countd, 'countd', np.nan)
        self.add_column(self.tableau_rt_inv_cur_count, 'rowcount', np.nan)
        self.add_column(self.tableau_rt_inv_cur_countd, 'countd', np.nan)
        self.add_column(self.tableau_rt_inv_cur_sum, 'sum', np.nan)
        self.add_column(self.tableau_rt_inv_mth_countd, 'countd', np.nan)
        self.add_column(self.tableau_rt_inv_mth_sum, 'sum', np.nan)
        self.add_column(self.tableau_rt_inv_mth_count, 'rowcount', np.nan)
        self.add_column(self.tableau_rt_dtarget_countd_yesterday, 'countd', 'yesterday')
        self.add_column(self.tableau_rt_dtarget_count_YTD, 'rowcount', 'ytd')
        self.add_column(self.tableau_rt_dtarget_sum_YTD, 'sum', 'ytd')
        self.add_column(self.tableau_rt_vip_mas_countd, 'countd', np.nan)

    def change_row_name(self):
        self.tableau_rt_dtarget_sum_YTD['dimension'] = 'shop'
        self.tableau_rt_inv_mth_sum['Measure Names'] = self.tableau_rt_inv_mth_sum['Measure Names'].str.replace(
            "CLOSING",
            "OPENING")
        self.tableau_rt_inv_mth_count['Measure Names'] = self.tableau_rt_inv_mth_count['Measure Names'].str.replace(
            "CLOSING",
            "OPENING")

    def change_col_name(self):
        self.tableau_rt_sales_info_sum_YTD = self.tableau_rt_sales_info_sum_YTD.rename(
            {'Measure Names': 'field', 'Measure Values': 'today_tableau_amount', 'table Name': 'table'}, axis=1)
        self.tableau_rt_sales_info_count_YTD = self.tableau_rt_sales_info_count_YTD.rename(
            {'Measure Names': 'field', 'Measure Values': 'today_tableau_amount', 'table Name': 'table'}, axis=1)
        self.tableau_rt_sales_info_countd_yesterday = self.tableau_rt_sales_info_countd_yesterday.rename(
            {'Measure Names': 'dimension', 'Measure Values': 'today_tableau_amount', 'table Name': 'table'}, axis=1)
        self.tableau_rt_shop_info_countd = self.tableau_rt_shop_info_countd.rename(
            {'Measure Names': 'dimension', 'Measure Values': 'today_tableau_amount', 'table Name (SHOP_INFO)': 'table'},
            axis=1)
        self.tableau_rt_inv_cur_count_YTD = self.tableau_rt_inv_cur_count_YTD.rename(
            {'Measure Names': 'field', 'Measure Values': 'today_tableau_amount', 'table Name': 'table'}, axis=1)
        self.tableau_rt_inv_cur_countd = self.tableau_rt_inv_cur_countd.rename(
            {'Measure Names': 'dimension', 'Measure Values': 'today_tableau_amount', 'table Name': 'table'}, axis=1)
        self.tableau_rt_inv_cur_sum_YTD = self.tableau_rt_inv_cur_sum_YTD.rename(
            {'Measure Names': 'field', 'Measure Values': 'today_tableau_amount', 'table Name': 'table'}, axis=1)
        self.tableau_rt_inv_mth_countd = self.tableau_rt_inv_mth_countd.rename(
            {'Measure Names': 'dimension', 'Measure Values': 'today_tableau_amount', 'table Name': 'table'}, axis=1)
        self.tableau_rt_inv_mth_sum = self.tableau_rt_inv_mth_sum.rename(
            {'Measure Names': 'field', 'Measure Values': 'today_tableau_amount', 'table Name': 'table'}, axis=1)
        self.tableau_rt_inv_mth_count = self.tableau_rt_inv_mth_count.rename(
            {'Measure Names': 'field', 'Measure Values': 'today_tableau_amount', 'table Name': 'table'}, axis=1)
        self.tableau_rt_dtarget_countd_yesterday = self.tableau_rt_dtarget_countd_yesterday.rename(
            {'Measure Names': 'dimension', 'Measure Values': 'today_tableau_amount', 'table Name': 'table'}, axis=1)
        self.tableau_rt_dtarget_count_YTD = self.tableau_rt_dtarget_count_YTD.rename(
            {'Measure Names': 'field', 'Measure Values': 'today_tableau_amount', 'table Name': 'table'}, axis=1)
        self.tableau_rt_dtarget_sum_YTD = self.tableau_rt_dtarget_sum_YTD.rename(
            {'Measure Names': 'field', 'Measure Values': 'today_tableau_amount', 'table Name': 'table'}, axis=1)
        self.tableau_rt_vip_mas_countd = self.tableau_rt_vip_mas_countd.rename(
            {'Measure Names': 'dimension', 'Measure Values': 'today_tableau_amount', 'table Name (VIP_INFO)': 'table'},
            axis=1)

    def df_operation(self):
        self.output_df = self.tableau_rt_sales_info_sum_YTD.append(
            [self.tableau_rt_sales_info_count_YTD,
             self.tableau_rt_sales_info_countd_yesterday,
             self.tableau_rt_shop_info_countd,
             self.tableau_rt_inv_cur_count_YTD,
             self.tableau_rt_inv_cur_countd,
             self.tableau_rt_inv_cur_sum_YTD,
             self.tableau_rt_inv_mth_countd,
             self.tableau_rt_inv_mth_sum,
             self.tableau_rt_inv_mth_count,
             self.tableau_rt_dtarget_countd_yesterday,
             self.tableau_rt_dtarget_count_YTD,
             self.tableau_rt_dtarget_sum_YTD,
             self.tableau_rt_vip_mas_countd], sort=False)

        self.output_df = self.output_df.reset_index(drop=True)
        self.output_df = self.output_df.applymap(lambda s: s.lower() if type(s) == str else s)
        self.output_df.columns = map(str.lower, self.output_df.columns)

        self.tlist = self.output_df.columns.values.tolist()
        self.tlist.remove('today_tableau_amount')

    def run(self):
        self.get_csv()
        self.read_csv()
        self.adding_col()
        self.change_row_name()
        self.change_col_name()
        self.df_operation()


# -----------------------------------------------------------------------------------------------------------------------

class get_db:

    def _init_(self):
        self.csv = pd.read_csv("input.csv")
        self.yesterday_df = pd.read_csv('snapshot_' + str(yesterday) + '.csv')
        self.df = pd.DataFrame
        self.alldf_snap = pd.DataFrame
        self.alldf_today = pd.DataFrame
        self.pssql_today = pd.DataFrame
        self.username = ""
        self.password = ""
        self.clist = self.csv.columns.values.tolist()
        self.ddlist = self.csv.columns.values.tolist()
        self.df_list_today = []
        self.df_list_snap = []
        self.list_postgre = ["table", "field", "method", "dimension"]
        self.df_postgra = pd.DataFrame(columns=["table", "field", "method"])
        self.column_list = []
        self.res_snapshot = []
        self.res = []
        self.res1 = []
        self.t_sales_olap = ["month", "pmt_status", "territory", "pmt_level", "sal_cst", "prod_cat_desc",
                             "shop_soh_amt", "shop_am", "trx_date", "zzfrc_flag", "cs_survey1_ans", "prod_cat",
                             "shop_curr_soh_qty", "last_gr_date", "prom_code", "dept_code", "vip_status", "chain_group",
                             "landlord_name", "mms_curr_soh_qty", "region", "shop_amdm", "curr_soh_qty",
                             "shop_curr_soh_amt", "shop_group_desc", "mall", "mms_curr_soh_amt", "long_run",
                             "is_indirect", "nationality", "brand_chain", "sal_amt", "curr_soh_amt", "brand_code",
                             "shop_desc", "shop_manager", "first_gr_date", "func_desc", "is_nike_markdown", "franc",
                             "shop_code_name", "trf_cnt", "generic_article", "chain", "pmt_remark", "mm1_target_gp",
                             "shop_dm", "pmt_start_d", "gender_desc", "last_mark_down_date", "sal_qty", "shop_group",
                             "style_desc", "trx_no", "shop_grade", "brand_type", "shop_location", "top_store",
                             "curr_price_on_sales", "gender_code", "style_no", "area", "invoice_type", "zzfrc_code",
                             "shop_type", "nodetype", "bti_item", "data_type", "mms_mth_soh_qty", "inv_by_100",
                             "curr_price", "orig_price_on_sales", "comp_shop", "mm1_target", "func_code", "disc_item",
                             "dept_desc", "inv_by_50", "mth_soh_qty", "pmt_end_d", "table names", "shop", "cost",
                             "daily_target", "brand_subtype", "mth_soh_amt", "daily_budget", "shop_soh_qty",
                             "orig_price", "gp", "zzfrc_brand", "agency", "item_season", "pos_traffic_count",
                             "brand_desc", "bti_price", "is_prom", "mms_soh_amt""trx_time", "table names-1",
                             "orig_rt_amt", "stor_loc", "bulk_pur_info", "sal_qty_group", "rec_type", "original_rt_amt",
                             "current_rt_amt", "nationality2", "first_gr_month"]
        self.testing = ["area", "article_type", "billing_type", "brand_chain", "brand_code", "brand_desc", "bti_item",
                        "bulk_pur_info", "central_code", "chain", "collection", "color_desc", "color_no", "comp_shop",
                        "cost", "count_hour", "coupon_deduct_amt", "cs_survey", "cs_survey1_ans", "curr_price",
                        "curr_price_on_sales", "current_price", "dept_code", "dept_desc", "discount_card", "extra_desc",
                        "features", "first_gr_date", "first_sh_dr_date", "first_wh_dr_date", "franc", "franc_brand",
                        "func_code", "func_desc", "gender_code", "gender_desc", "generic_article", "gp_amt", "int_size",
                        "invoice_type", "item_season", "landlord_name", "last_gr_date", "last_mark_down_date",
                        "launch_month", "long_run", "mall", "meins", "merch_cat", "mkt_segment", "mm_chain_group",
                        "mm_shop_group", "nodetype", "orig_price", "orig_price_on_sales", "original_price",
                        "original_rt_amt", "pattern", "pmt_end_d", "pmt_level", "pmt_msg", "pmt_remark", "pmt_start_d",
                        "pmt_status", "pos_db_name", "pos_traffic_count", "prod_cat", "prod_cat_desc", "prod_segment",
                        "prod_story", "prod_sub_cat", "prod_sub_cat_desc", "prom_code", "promotion_code",
                        "rebated_sal_cst", "rec_type", "sal_amt", "sal_cst", "sal_qty", "sales_amount", "sales_cost",
                        "sales_org", "sales_qty", "series", "ship_mode", "shop", "shop_am", "shop_amdm",
                        "shop_code_name", "shop_desc", "shop_dm", "shop_grade", "shop_group",
                        "shop_group_desc""shop_location", "shop_manager", "shop_region", "shop_type", "size_profile",
                        "src_design_mode", "src_region", "src_source", "standard_cost", "stor_loc", "style_desc",
                        "style_no", "survey_nationality", "technology", "territory", "transaction_season", "trx_date",
                        "trx_date_mm", "trx_date_yyyy", "trx_no", "trx_time", "vendor_article", "vip_status", "vipcode",
                        "void_no", "volume", "zzbrand_class", "zzbrand_subtype", "zzfrc_brand", "zzfrc_code",
                        "zzfrc_flag", "zzz_banner", "zzz_brand", "zzz_brand_desc", "zzz_chain", "zzz_dep"]
        self.t_soh_olap = ["area", "article_type", "brand_chain", "brand_code", "brand_desc", "brand_subtype",
                           "brand_type", "central_code", "chain", "chain_group", "collection", "color_desc", "color_no",
                           "comp_shop", "core_point", "cost", "curr_price", "current_price", "dept_code", "dept_desc",
                           "extra_desc", "features", "first_gr_date", "first_sh_dr_date", "first_wh_dr_date", "franc",
                           "franc_brand", "func_code", "func_desc", "gender_code", "gender_desc", "generic_article",
                           "in_stock_point", "inv_batch_season", "is_indirect", "is_mms", "item_season",
                           "landlord_name", "last_gr_date", "last_mark_down_date", "launch_month", "long_run", "mall",
                           "meins", "merch_cat", "mkt_segment", "month", "nodetype", "opening_soh_amt",
                           "opening_soh_qty", "orig_price", "original_price", "pattern", "pos_traffic_count",
                           "prod_cat", "prod_cat_desc", "prod_segment", "prod_story", "prod_sub_cat",
                           "prod_sub_cat_desc", "sal_qty", "sales_type", "seasongp", "series", "ship_cost", "ship_mode",
                           "ship_qty", "shop", "shop_am", "shop_amdm", "shop_code_name", "shop_desc", "shop_dm",
                           "shop_grade", "shop_group", "shop_group_desc", "shop_location", "shop_manager",
                           "shop_region", "shop_type", "size_profile", "soh_amt", "soh_qty", "src_design_mode",
                           "src_region", "src_source", "standard_cost", "stor_loc", "style_desc", "style_no",
                           "technology", "territory", "total_point", "trx_date", "vendor_article", "volume",
                           "zzbrand_class", "zzfrc_brand", "zzfrc_code", "zzfrc_flag"]
        self.run()

    #     -------------------------------------------------------------------------------------------------

    #     def checking_and_merge_tab(self):

    #         self.df_final["tab_result"] = "nan"

    #         for i in range(len(self.df_final)):
    #             if not pd.isna(self.df_final.iloc[i]["today_tableau_amount"]) and not pd.isna(
    #                     self.df_final.iloc[i]["today_amount"]):
    #                 if self.df_final.iloc[i]["today_tableau_amount"] == self.df_final.iloc[i]["today_amount"]:
    #                     self.df_final.iloc[i, self.df_final.columns.get_loc("tab_result")] = "pass"
    #                 else:
    #                     self.df_final.iloc[i, self.df_final.columns.get_loc("tab_result")] = "fail"
    #         return self.df_final

    # -------------------------------------------------------------------------------------------

    def create_dic(self, c):
        if pd.isna(self.csv.loc[c]["dimension"]) and self.csv.loc[c]["field"]:
            print("case 1,", end=" ")
            if self.csv.loc[c]["field"] in self.t_sales_olap:
                table = "t_sales_olap"
                return table
            elif self.csv.loc[c]["field"] in self.t_soh_olap:
                table = "t_soh_olap"
                return table
            else:
                table = "error"
                return table

        elif self.csv.loc[c]["dimension"] and pd.isna(self.csv.loc[c]["field"]):
            print("case 2,", end=" ")
            if self.csv.loc[c]["dimension"] in self.t_sales_olap:
                table = "t_sales_olap"
                return table
            elif self.csv.loc[c]["dimension"] in self.t_soh_olap:
                table = "t_soh_olap"
                return table
            else:
                table = "error"
                return table

        elif self.csv.loc[c]["dimension"] and self.csv.loc[c]["field"]:
            print("case 3,", end=" ")
            if self.csv.loc[c]["field"] in self.t_sales_olap:
                table = "t_sales_olap"
                return table
            else:
                table = "error"
                return table

        else:
            print("case 4,", end=" ")
            pass

    def create_table_postgra(self, date):
        for i in range(len(self.csv)):  # en(self.csv)
            table = self.create_dic(i)
            print("table name = ", table, end=", ")

            if table != "error":
                self.db_query = DBQuery_SQL("postgre", "data123!", "mm", table)
                if self.csv.loc[i]["method"] == "rowcount":
                    print("\r")
                    continue

                elif self.csv.loc[i]["method"] == "countd":
                    self.db_query.add_dimensions([self.csv.loc[i]["dimension"]])
                    self.filter_(date, i, self.db_query)
                    print("postgresql")
                    self.df = self.db_query.run()
                    self.df = self.df.nunique()
                    self.df = self.df.to_frame(name=self.csv.loc[i]["dimension"])
                    self.df["table"] = self.csv.loc[i]["table"]
                    self.df["field"] = self.csv.loc[i]["field"]
                    self.df["method"] = self.csv.loc[i]["method"]
                    self.df["dimension"] = self.csv.loc[i]["dimension"]
                    self.df = self.df.reset_index(drop=True)
                    self.df.rename(columns={str(self.csv.loc[i]["dimension"]): 'pssql_amount'}, inplace=True)
                    self.df_postgra = pd.concat([self.df_postgra, self.df], axis=0, join='outer', sort=True)
                    print(self.df_postgra)


                else:
                    if pd.notnull(self.csv.loc[i]["dimension"]):
                        collist = ["field", "method"]
                        self.db_query.add_dimensions(self.csv.loc[i]["dimension"].split(","))
                        self.db_query.add_measure(self.csv.loc[i]["field"], self.csv.loc[i]["method"])
                        self.filter_(date, i, self.db_query)
                        print("postgresql")
                        self.df = self.db_query.run()
                        self.df = self.df.sort_values(by=self.csv.loc[i]["dimension"].split(","))
                        if pd.notnull(self.csv.loc[i]["dimension"]):
                            self.list_postgre = self.list_postgre + self.csv.loc[i]["dimension"].split(",")
                        print(self.list_postgre)
                        self.df["table"] = self.csv.loc[i]["table"]
                        self.df["field"] = self.csv.loc[i]["field"]
                        self.df["method"] = self.csv.loc[i]["method"]
                        self.df["dimension"] = self.csv.loc[i]["dimension"]
                        self.df.rename(columns={str(self.csv.loc[i]["field"]): 'pssql_amount'}, inplace=True)
                        self.df_postgra = pd.concat([self.df_postgra, self.df], axis=0, join='outer', sort=True)



                    else:
                        self.db_query.add_measure(self.csv.loc[i]["field"], self.csv.loc[i]["method"])
                        self.filter_(date, i, self.db_query)
                        print("postgresql")
                        self.df = self.db_query.run()
                        self.df["table"] = self.csv.loc[i]["table"]
                        self.df["field"] = self.csv.loc[i]["field"]
                        self.df["method"] = self.csv.loc[i]["method"]
                        self.df["dimension"] = self.csv.loc[i]["dimension"]
                        self.df.rename(columns={str(self.csv.loc[i]["field"]): 'pssql_amount'}, inplace=True)
                        self.df_postgra = pd.concat([self.df_postgra, self.df], axis=0, join='outer', sort=True)
            else:
                print("\r")
                pass

    #   -------------------------------------------------------------------------------------------------------

    def create_table_oracle(self, d_list, date, table_name):
        for i in range(len(self.csv)):
            self.db_query = DBQuery(self.username, self.password, "srlbiprod", self.csv.loc[i]["table"])
            if self.csv.loc[i]["method"] == "countd":
                self.table_countd(i, d_list, date, table_name)
            else:
                if pd.notnull(self.csv.loc[i]["dimension"]):
                    self.table_sum(i, d_list, date, table_name)
                else:
                    self.table_rowcount(i, d_list, date, table_name)

    def table_countd(self, c, dataframe_list, day, table_name):
        self.db_query.add_dimensions([self.csv.loc[c]["dimension"]])
        self.filter_(day, c, self.db_query)
        print(table_name)
        dataframe_list.append("df" + str(c))
        self.df = self.db_query.run()
        self.df = self.df.nunique()
        self.df = self.df.to_frame(name=self.csv.loc[c]["dimension"])
        self.df = self.df.reset_index(drop=True)
        dataframe_list[c] = self.df
        self.writter(dataframe_list, c)

    def table_sum(self, c, dataframe_list, day, table_name):  # not sum, is spilt dimension
        self.db_query.add_dimensions(self.csv.loc[c]["dimension"].split(","))
        self.db_query.add_measure(self.csv.loc[c]["field"], self.csv.loc[c]["method"])
        self.filter_(day, c, self.db_query)
        print(table_name)
        dataframe_list.append("df" + str(c))
        dataframe_list[c] = self.db_query.run()
        if pd.notnull(self.csv.loc[c]["dimension"]):
            dataframe_list[c] = dataframe_list[c].sort_values(by=self.csv.loc[c]["dimension"].split(","))
        self.writter(dataframe_list, c)
        self.column(c)

    def table_rowcount(self, c, dataframe_list, day, table_name):  # not rowcount, is without split dimension
        self.db_query.add_measure(self.csv.loc[c]["field"], self.csv.loc[c]["method"])
        self.filter_(day, c, self.db_query)
        print(table_name)
        dataframe_list.append("df" + str(c))
        dataframe_list[c] = self.db_query.run()
        self.writter(dataframe_list, c)

    def column(self, c):
        self.clist = self.clist + self.csv.loc[c]["dimension"].split(",")

    def filter_(self, date, c, db):
        print(c, " / ", len(self.csv) - 1, " ", end=" ")
        if pd.notnull(self.csv.loc[c]["period_type"]):
            if self.csv.loc[c]["period_type"] == "yesterday":
                db.add_filter_condition('trx_date', 'eq', str(yesterday).replace("-", ""))
            else:
                db.add_filter_condition('trx_date', 'btw',
                                        [str(period_to_date(today, self.csv.loc[c, "period_type"])[0]).replace("-", ""),
                                         str(date).replace("-", "")])
        else:
            pass

    def writter(self, df_list, c):
        self.column_list = self.csv.columns.values.tolist()
        for k in self.csv.columns:
            df_list[c][k] = self.csv.loc[c][k]
        if pd.notnull(self.csv.loc[c]["dimension"]):
            self.column_list = self.column_list + self.csv.loc[c]["dimension"].split(",")
        if self.csv.loc[c]["method"] != "countd":
            self.column_list.append(self.csv.loc[c]["field"])
        df_list[c] = df_list[c].reindex(columns=self.column_list)
        df_list[c].rename(columns={str(self.csv.loc[c]["field"]): 'today_amount'}, inplace=True)
        if self.csv.loc[c]["method"] == "countd":
            df_list[c].rename(columns={str(self.csv.loc[c]["dimension"]): 'today_amount'}, inplace=True)

    def setup_col(self):
        self.res_snapshot = [i for n, i in enumerate(self.clist) if i not in self.clist[:n]]
        self.res = [i for n, i in enumerate(self.clist) if i not in self.clist[:n]]
        self.res1 = [i for n, i in enumerate(self.clist) if i not in self.clist[:n]]
        self.res_snapshot = self.res_snapshot.append("snapshot_amount")
        self.res = self.res.append("today_amount")

    def combine(self):
        self.alldf_snap = pd.concat(self.df_list_snap, axis=0, join='outer')
        self.alldf_snap = self.alldf_snap.reindex(columns=self.res)
        self.alldf_snap = self.alldf_snap.reset_index(drop=True)
        self.alldf_today = pd.concat(self.df_list_today, axis=0, join='outer')
        self.alldf_today = self.alldf_today.reindex(columns=self.res)
        self.alldf_today = self.alldf_today.reset_index(drop=True)

    def fill_and_merge(self):
        self.yesterday_df = self.yesterday_df.rename(columns={"today_amount": "snapshot_amount"})
        self.alldf_today = self.alldf_today.fillna("**")
        self.yesterday_df = self.yesterday_df.fillna("**")
        print(self.alldf_today.dtypes)
        print(self.yesterday_df.dtypes)
        self.alldf_today = self.alldf_today.replace("**", "")
        self.yesterday_df = self.yesterday_df.replace("**", "")
        print(self.alldf_today)
        print(self.yesterday_df)
        print(self.alldf_today.dtypes)
        print(self.yesterday_df.dtypes)

        self.alldf_today = pd.merge(self.alldf_today, self.yesterday_df, on=self.res_snapshot, how='left')
        print(self.alldf_today.head())
        self.alldf_today = self.alldf_today.fillna("**")
        self.alldf_today = self.alldf_today.replace("**", "")
        self.alldf_today = self.alldf_today.fillna("")
        self.alldf_today["allowance"] = pd.to_numeric(self.alldf_today["allowance"])
        self.alldf_today["today_amount"] = pd.to_numeric(self.alldf_today["today_amount"])
        self.alldf_today = self.alldf_today.fillna("")

    def checker_interval(self, c):
        if self.alldf_today.iloc[c]["today_amount"] <= (1 + self.alldf_today.iloc[c]["allowance"]) * \
                self.alldf_today.iloc[c]["snapshot_amount"] and self.alldf_today.iloc[c]["today_amount"] >= (
                1 - self.alldf_today.iloc[c]["allowance"]) * self.alldf_today.iloc[c]["snapshot_amount"]:
            self.alldf_today.iloc[c, self.alldf_today.columns.get_loc("result")] = "pass"
        else:
            self.alldf_today.iloc[c, self.alldf_today.columns.get_loc("result")] = "fail"

    def checker_equal(self, c):
        if self.alldf_today.iloc[c]["today_amount"] == self.alldf_today.iloc[c]["snapshot_amount"]:
            self.alldf_today.iloc[c, self.alldf_today.columns.get_loc("result")] = "pass"
        else:
            self.alldf_today.iloc[c, self.alldf_today.columns.get_loc("result")] = "fail"

    def checker_between(self, c):
        if self.alldf_today.iloc[c]["today_amount"] <= self.alldf_today.iloc[c]["snapshot_amount"] + \
                self.alldf_today.iloc[c]["allowance"] and self.alldf_today.iloc[c]["today_amount"] >= \
                self.alldf_today.iloc[c]["snapshot_amount"] - self.alldf_today.iloc[c]["allowance"]:
            self.alldf_today.iloc[c, self.alldf_today.columns.get_loc("result")] = "pass"
        else:
            self.alldf_today.iloc[c, self.alldf_today.columns.get_loc("result")] = "fail"

    def checker_nondecresing(self, c):
        if self.alldf_today.iloc[c]["today_amount"] >= self.alldf_today.iloc[c]["snapshot_amount"]:
            self.alldf_today.iloc[c, self.alldf_today.columns.get_loc("result")] = "pass"
        else:
            self.alldf_today.iloc[c, self.alldf_today.columns.get_loc("result")] = "fail"

    def checker_new_or_error(self, c):
        if self.alldf_today.iloc[c]["today_amount"] == '':
            self.alldf_today.iloc[c, self.alldf_today.columns.get_loc("result")] = "without_today_amount_error"
        else:
            self.alldf_today.iloc[c, self.alldf_today.columns.get_loc("result")] = "new"

    def checking(self):

        self.alldf_today["result"] = 0

        for i in range(len(self.alldf_today)):

            try:
                if self.alldf_today.iloc[i]["snapshot_amount"] != "":

                    if self.alldf_today.iloc[i]["comp_type"] == "interval":
                        self.checker_interval(i)

                    elif self.alldf_today.iloc[i]["comp_type"] == "equal":
                        self.checker_equal(i)

                    elif self.alldf_today.iloc[i]["comp_type"] == "between":
                        self.checker_between(i)

                    elif self.alldf_today.iloc[i]["comp_type"] == "nondecresing":
                        self.checker_nondecresing(i)

                else:
                    self.checker_new_or_error(i)

            except Exception as e:
                self.alldf_today.iloc[i, self.alldf_today.columns.get_loc("result")] = ("Error -- ", str(e))

    def checking_and_merge_pssql(self):
        print(self.alldf_today)
        self.pssql_today = self.alldf_today
        clist = [i for n, i in enumerate(self.list_postgre) if i not in self.list_postgre[:n]]
        print(clist)
        print("\r")
        self.df_postgra = self.df_postgra.fillna("")
        self.pssql_today = pd.merge(self.pssql_today, self.df_postgra, on=clist, how='left')
        self.pssql_today["pssql_amount"] = pd.to_numeric(self.pssql_today["pssql_amount"])
        self.pssql_today["today_amount"] = pd.to_numeric(self.pssql_today["today_amount"])

        self.pssql_today["pgsql_result"] = "nan"
        for i in range(len(self.pssql_today)):
            if not pd.isna(self.pssql_today.iloc[i]["pssql_amount"]) and not pd.isna(
                    self.pssql_today.iloc[i]["today_amount"]):
                if int(self.pssql_today.iloc[i]["pssql_amount"]) == int(self.pssql_today.iloc[i]["today_amount"]):
                    self.pssql_today.iloc[i, self.pssql_today.columns.get_loc("pgsql_result")] = "pass"
                else:
                    self.pssql_today.iloc[i, self.pssql_today.columns.get_loc("pgsql_result")] = "fail"
        return self.pssql_today

    # -------------------------------------------------------------------------------------------------------------------
    def clean_amount(self, x):
        if isinstance(x, str):
            return (x.replace(',', ''))
        return (x)

    def merge_check_postgre_and_tablu(self):
        tablu = tab()
        tablue = tablu.output_df
        tablue = tablue.fillna("")
        self.pssql_today = self.pssql_today.applymap(lambda s: s.lower() if type(s) == str else s)
        self.pssql_today.columns = map(str.lower, self.pssql_today.columns)
        tablu.tlist

        self.pssql_today = pd.merge(self.pssql_today, tablue, on=tablu.tlist, how='left')
        self.pssql_today['today_tableau_amount'] = self.pssql_today['today_tableau_amount'].apply(
            self.clean_amount).astype('float')

        self.pssql_today["today_tableau_amount"] = pd.to_numeric(self.pssql_today["today_tableau_amount"])
        self.pssql_today["today_amount"] = pd.to_numeric(self.pssql_today["today_amount"])

        self.pssql_today["tab_result"] = "nan"

        for i in range(len(self.pssql_today)):
            if not pd.isna(self.pssql_today.iloc[i]["today_tableau_amount"]) and not pd.isna(
                    self.pssql_today.iloc[i]["today_amount"]):
                if int(self.pssql_today.iloc[i]["today_tableau_amount"]) == int(self.pssql_today.iloc[i]["today_amount"]):
                    self.pssql_today.iloc[i, self.pssql_today.columns.get_loc("tab_result")] = "pass"
                else:
                    self.pssql_today.iloc[i, self.pssql_today.columns.get_loc("tab_result")] = "fail"
        return self.pssql_today

    # --------------------------------------------------------------------------------------------------------------------------------
    def output(self):
        self.alldf_snap.to_csv('snapshot_' + str(today) + '.csv', index=False, header=True)
        self.alldf_today = self.alldf_today.fillna("")
        self.alldf_today.to_csv('result_' + str(today) + '.csv', index=False, header=True)

        self.pssql_today.to_csv('result_pssql_' + str(today) + '.csv', index=False, header=True)

    def view_snap(self):
        return self.alldf_snap.head(10)

    def view_today(self):
        return self.alldf_today.head(10)

    def run(self):
        self.create_table_oracle(self.df_list_today, yyesterday, "oracle_today")
        self.create_table_oracle(self.df_list_snap, yesterday, "oracle_snapshot")
        self.setup_col()
        self.combine()
        self.fill_and_merge()
        self.checking()

        self.create_table_postgra(yyesterday)
        self.checking_and_merge_pssql()

        self.merge_check_postgre_and_tablu()
        print(" done")

    def reporting(self):
        self.report = pd.DataFrame
        self.pass_count = str(len(self.alldf_today) - len(self.alldf_today[self.alldf_today['result'] != 'pass']))
        self.report = self.alldf_today[self.alldf_today['result'] != 'pass']
        print("Number of rules run/passed: ", self.pass_count, " / ", str(len(self.alldf_today)))
        print("Details:")
        print(self.report)


if _name_ == "_main_":
    program = get_db()
    program.output()
    program.reporting()

# status# status

# status# status
